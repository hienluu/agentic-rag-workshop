{
    "page_url": "https://qconlondon.com/presentation/apr2025/beyond-warehouse-why-bigquery-alone-wont-solve-your-data-problems",
    "page_title": "QCon London 2025 | Beyond the Warehouse: Why BigQuery Alone Won\u2019t Solve Your Data Problems",
    "page_content": "Your choice regarding cookies on this site\nWe use cookies to optimise site functionality and give you the best possible experience.\nI AcceptI RejectCookie Preferences\nYou are viewing content from a past/completed conference.\n# Beyond the Warehouse: Why BigQuery Alone Won\u2019t Solve Your Data Problems\n### Summary\nDisclaimer: This summary has been generated by AI. It is experimental, and feedback is welcomed. Please reach out to info@qconlondon.com with any comments or concerns. \nThe presentation titled _Beyond the Warehouse: Why BigQuery Alone Won\u2019t Solve Your Data Problems_ by Sarah Usher focuses on the limitations of relying solely on BigQuery or any data warehouse to solve extensive data challenges. Sarah emphasizes the importance of a comprehensive data strategy and architecture to truly harness data's potential.\n**Key Points:**\n  * **Limitations of Data Warehouses:** Data warehouses like BigQuery can effectively manage data for a time but may struggle with latency and scalability as data complexity and sources increase. This can lead organizations to incorrectly view a warehouse as a solution to all data problems.\n  * **Data Strategy Essentials:** A robust data strategy involves storing and curating raw data before it enters the warehouse. This enables flexibility, allowing for changes without compromising the data's integrity.\n  * **Importance of Raw Data Storage:** Storing raw data in its original form is crucial to allow for reprocessing and adapting to new architectures or data tools.\n  * **Data Curation and Usage:** Curated data should be maintained alongside raw data, providing a clean, standardized version for specific use cases and preventing reprocessing burdens.\n  * **Source of Truth Concept:** Instead of relying on the warehouse as the single source of truth, the presentation suggests designing a more flexible approach whereby the source of truth is determined at a curated layer, allowing for diverse implementations.\n\n\nSarah concludes by encouraging organizations to store raw data diligently and rethink their data architecture beyond just the warehouse, fostering innovation and sustainability.\nThis is the end of the AI-generated content.\n* * *\n### Abstract\nMany organizations mistake the adoption of a data warehouse, like BigQuery, as the golden ticket to solving all their data challenges. But without a robust data strategy and architecture, you\u2019re simply shifting chaos into the cloud. This talk explores why a warehouse is just one piece of the puzzle and dives into the tools, processes, and structures that can enhance your architecture beyond the warehouse. We\u2019ll also cover practical strategies for recovering from poorly implemented data systems and building sustainable and adaptable data infrastructure.\n## Interview:\n### What is the focus of your work?\nI specialise in data software engineering and architecture, that enables effective data management to meet business needs. My work often involves designing and building systems that can handle increasing complexity - whether due to data volume, multiple sources, various integrations, or innovative applications of data.\n### What\u2019s the motivation for your talk?\nI've been discussing this topic for years because I've seen firsthand how poor data architecture can hinder companies. My goal is to help change that by sharing insights and best practices to change the status quo in data tech.\n### Who is your talk for?\nMy talk is for architects, engineers, and anyone responsible for shaping how data flows within an organisation.\n### What do you want someone to walk away with from your presentation?\nA clear understanding of what good data architecture looks like, practical ideas for improving their own systems, and the realisation that they don\u2019t have to accept the status quo. Every data system can be improved.\n### What do you think is the next big disruption in software?\nI think we'll see an expansion of AI in automation. Whether one agrees with this direction or not, it will demand higher-quality data and more robust security practices than we currently have today.\n* * *\n### Speaker\n#### Sarah Usher\nData & Backend Engineer, Community Director, Mentor\nSpeaker bio: Sarah is a software engineer specialising in data engineering, backend systems, and scalable system design. She has extensive experience across industries such as banking, insurance, developer security, and digital advertising. Sarah excels in tackling challenges of scale - not just in terms of load or data size, but also data complexity. In addition to her technical work, Sarah is an active contributor to the tech community, regularly running talks, workshops, and training sessions through initiatives like Tech Risers Women, Women in Data, and Ladies of Code. She has won awards for her mentorship and leadership.\nRead more\n#####  Find Sarah Usher at: \n  *   * \n\n#### Speaker\n##### Sarah Usher\nData & Backend Engineer, Community Director, Mentor\n#### Date\nWednesday Apr 9 / 03:55PM BST ( 50 minutes )\n#### Location\nWhittle (3rd Fl.)\n#### Track\nModern Data Architectures\n#### Topics\nData Architecture System Design scalability\n#### Share\nShare Share\n## From the same track\nSession Data Architecture\n### Reliable Data Flows and Scalable Platforms: Tackling Key Data Challenges\nWednesday Apr 9 / 10:35AM BST\nThere are a few common and mostly well-known challenges when architecting for data. For example, many data teams struggle to move data in a stable and reliable way from operational systems to analytics systems. \nMatthias Niehoff\nHead of Data and Data Architecture @codecentric AG, iSAQB Certified Professional for Software Architecture\nReliable Data Flows and Scalable Platforms: Tackling Key Data Challenges\nSession AI/ML\n### Achieving Precision in AI: Retrieving the Right Data Using AI Agents\nWednesday Apr 9 / 11:45AM BST\nIn the race to harness the power of generative AI, organizations are discovering a hidden challenge: precision. \nAdi Polak\nDirector, Advocacy and Developer Experience Engineering @Confluent, Author of \"Scaling Machine Learning with Spark\" and \"High Performance Spark 2nd Edition\"\nAchieving Precision in AI: Retrieving the Right Data Using AI Agents\nSession AI/ML\n### The Data Backbone of LLM Systems\nWednesday Apr 9 / 02:45PM BST\nAny LLM application has four dimensions you must carefully engineer: the code, data, models and prompts. Each dimension influences the other. That's why you must learn how to track and manage each. The trick is that every dimension has particularities requiring unique strategies and tooling. \nPaul Iusztin\nSenior ML/AI Engineer, MLOps, Founder @Decoding ML\nThe Data Backbone of LLM Systems\nSession\n### Panel: Modern Data Architectures\nWednesday Apr 9 / 01:35PM BST\nPanel: Modern Data Architectures\n"
}