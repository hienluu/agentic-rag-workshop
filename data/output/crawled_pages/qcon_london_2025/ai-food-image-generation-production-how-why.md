{
    "page_url": "https://qconlondon.com/presentation/apr2025/ai-food-image-generation-production-how-why",
    "page_title": "QCon London 2025 | AI for Food Image Generation in Production: How & Why",
    "page_content": "Your choice regarding cookies on this site\nWe use cookies to optimise site functionality and give you the best possible experience.\nI AcceptI RejectCookie Preferences\nYou are viewing content from a past/completed conference.\n# AI for Food Image Generation in Production: How & Why\n### Summary\nDisclaimer: This summary has been generated by AI. It is experimental, and feedback is welcomed. Please reach out to info@qconlondon.com with any comments or concerns. \n**AI for Food Image Generation in Production: How & Why**\nThis presentation explores the development lifecycle and implementation of a food image generation solution at Delivery Hero, highlighting the technical and business aspects of using AI for generating food images. Presented by Iaroslav Amerkhanov, it outlines the process from hypothesis to scalable deployment.\n  * _Business Rationale:_ The project aims to improve menu content quality, hypothesizing that better content enhances conversion rates. Initial data showed that 86% of products with images had higher conversion rates, emphasizing the need for image generation over text descriptions.\n  * _Technical Approach:_ The development involved creating a Minimum Viable Product (MVP) using Google Cloud Platform (GCP) and optimizing the image generation models for efficiency. Key components included text-to-image generation and in-painting techniques.\n  * _Image Quality Control:_ Comprehensive quality checks ensured the consistency and appropriateness of generated images. This involved object detection, bounding box checks, and color adjustments using computer vision models.\n  * _Production Scaling:_ The transition to production involved migrating models to self-hosted solutions to optimize costs. The deployment utilized NVIDIA GPUs and optimized stable diffusion models for better performance.\n  * _Results and Impact:_ The solution generated over a million images, covering over 100,000 products, and achieved a 6-8% increase in conversion rates through A/B testing.\n  * _Challenges and Solutions:_ Issues with non-Latin language support and large prompt processing were solved by translations and chunking methods. Also, a safety system was implemented for content validation to ensure image quality.\n  * _Learnings:_ Key takeaways include the importance of infrastructure optimization and the need for robust quality measurement mechanisms before model fine-tuning. Avoiding cross-cloud implementations unless necessary was also advised.\n\n\nOverall, this session illustrated the significant business impact and technical challenges of implementing AI-driven solutions in the food delivery sector, with a focus on generating high-quality visual content at scale.\nThis is the end of the AI-generated content.\n* * *\n### Abstract\nIn this talk, we will conduct a technical overview of a client-facing Food Image Generation solution developed at Delivery Hero. We will explore step-by-step the stages of the product development cycle starting from an initial business hypothesis, following up with the fast-to-market product validation MVP and the full-scale productization phase that enabled generating 100,000 images per day.\nThe first focus of our discussion will be on the modern approaches in Image Generation that enable the generation of high-quality food-related visual content. We will explore the challenges of experimenting with the image generation models, the evaluation techniques and the ways to fine-tune these models. We'll also cover a set of advanced Computer Vision methods that help maintain high standards of visual content quality by automatic validation of the images across dimensions like positioning, colour balance, appropriateness and content relevance.\nWe will also consider the practical aspects of serving and scaling the visual models in production depending on the maturity level of the product and the infrastructure. Following up with the technical stack, we will outline the most appropriate approaches for each of the stages focusing on cost-efficiency, as well as the architectural decisions made at Delivery Hero to host and scale a zoo of visual models.\n## Interview:\n### What is the focus of your work?\nAs a Senior Data Scientist at Delivery Hero, I'm leading the AI-related projects of the AI Menu Content team. Our main products cover image generation and image enhancement problems. The development process includes several steps: data curation and labeling, modeling, experimentation, and integration into production. Our model zoo includes a set of Computer Vision and Image Generation methods based on the latest advancements in the area, which makes it highly fascinating to work with.\n### What\u2019s the motivation for your talk?\nThe primary goal behind my speech is to motivate more teams in the industry to work on the image generation problem. That's why I'm excited to demonstrate the business case and the value such work could bring to a company.\n### Who is your talk for?\nThe talk targets AI & ML leaders and practitioners: we'll go through the business foundations and impact, following up with the methods used and the details on how the models are served in production. The focus will be on the applied part of the story and the real-world use cases.\n### What do you want someone to walk away with from your presentation?\nWith such rapid development in the area of deep learning and AI in general, many companies still wait for a broader adoption of these technologies in the industry before investing in them. The most important point I'd like to make clear is that with the modern stack of available frameworks, cloud services, and open-source models it's possible to achieve low time-to-market, making such investments justified.\n### What do you think is the next big disruption in software?\nThe AI agents which are capable of effectively utilizing the desktop setup and interacting with web services have the potential to disrupt the industry once their generalization capabilities and cost-efficiency reach a certain level. We can already see the first steps in this direction with the models from Anthropic and Open AI. It's obvious that the communication interfaces will evolve with time, potentially creating a new industry of AI-tailored operating systems and services.\n* * *\n### Speaker\n#### Iaroslav Amerkhanov\nSenior Data Scientist @Delivery Hero, Founder of T4lky, Creator & Host of EPAM Podcast, Speaker\nIaroslav pioneered projects in Food Science at Delivery Hero and is now focused on generative AI solutions. He previously founded an EdTech startup and co-founded a sentiment analysis platform.\nRead more\n#####  Find Iaroslav Amerkhanov at: \n  *   * \n\n#### Speaker\n##### Iaroslav Amerkhanov\nSenior Data Scientist @Delivery Hero, Founder of T4lky, Creator & Host of EPAM Podcast, Speaker\n#### Date\nTuesday Apr 8 / 01:35PM BST ( 50 minutes )\n#### Location\nWhittle (3rd Fl.)\n#### Track\nAI and ML for Software Engineers: Foundational Insights\n#### Topics\nAI/ML Image Generation computer vision stable diffusion\n#### Slides\nSlides are not available\n#### Share\nShare Share\n## From the same track\nSession AI/ML\n### Deploy MultiModal RAG Systems with vLLM\nTuesday Apr 8 / 10:35AM BST\nWhile text-based RAG systems have been everywhere in the last year and a half, there is so much more than text data. Images, audio, and documents often need to be processed together to provide meaningful insights, yet most RAG implementations focus solely on text. \nStephen Batifol\nDeveloper Advocate @Zilliz, Founding Member of the MLOps Community Berlin, Previously Machine Learning Engineer @Wolt, and Data Scientist @Brevo\nDeploy MultiModal RAG Systems with vLLM\nSession AI/ML\n### How to Unlock Insights and Enable Discovery Within Petabytes of Autonomous Driving Data\nTuesday Apr 8 / 05:05PM BST\nFor autonomous vehicle companies, finding valuable insights within millions of hours of video data is essential yet challenging. \nKyra Mozley\nML Engineer @Wayve, Previously Security & AI PhD Candidate @Royal Holloway University\nHow to Unlock Insights and Enable Discovery Within Petabytes of Autonomous Driving Data\nSession AI/ML\n### Foundation Models for Ranking: Challenges, Successes, and Lessons Learned\nTuesday Apr 8 / 02:45PM BST\nRecommender systems are an integral part of most products nowadays and are often a key driver of discovery for users of the product. \nMoumita Bhattacharya\nSenior Research Scientist @Netflix, Previously @Etsy\nFoundation Models for Ranking: Challenges, Successes, and Lessons Learned\nSession AI/ML\n### Building Embedding Models for Large-Scale Real-World Applications\nTuesday Apr 8 / 03:55PM BST\nEmbedding models are at the core of search, recommendation, and retrieval-augmented generation (RAG) systems, transforming data into meaningful representations. \nSahil Dua\nSenior Software Engineer, Machine Learning @Google, Stanford AI, Co-Author of \u201cThe Kubernetes Workshop\u201d, Open-Source Enthusiast \nBuilding Embedding Models for Large-Scale Real-World Applications\nSession\n### Unconference: AI and ML for Software Engineers\nTuesday Apr 8 / 11:45AM BST\nUnconference: AI and ML for Software Engineers\n"
}