{
    "page_url": "https://qconlondon.com/presentation/apr2025/building-embedding-models-large-scale-real-world-applications",
    "page_title": "QCon London 2025 | Building Embedding Models for Large-Scale Real-World Applications",
    "page_content": "Your choice regarding cookies on this site\nWe use cookies to optimise site functionality and give you the best possible experience.\nI AcceptI RejectCookie Preferences\nYou are viewing content from a past/completed conference.\n# Building Embedding Models for Large-Scale Real-World Applications\n### Summary\nDisclaimer: This summary has been generated by AI. It is experimental, and feedback is welcomed. Please reach out to info@qconlondon.com with any comments or concerns. \nThe presentation titled _Building Embedding Models for Large-Scale Real-World Applications_ by Sahil Dua discusses the fundamental aspects and practical insights into deploying embedding models in large-scale applications. Here is a structured summary of the key points from the presentation:\n  * **Introduction to Embedding Models:**\n    * Embedding models transform data into meaningful vector representations, useful in various applications like search, recommendations, and retrieval-augmented generation (RAG).\n    * Embeddings for similar inputs are close to each other in the vector space, while different inputs are far apart.\n  * **Applications:**\n    * Retrieving the best matching documents, passages, images, or videos from vast data collections.\n    * Generating personalized recommendations based on user preferences.\n    * RAG applications for enhancing language model outputs with factual accuracy.\n  * **Model Lifecycle:**\n    * Designing architectures that cater to specific serving requirements.\n    * Distilling large models into smaller, efficient productions models.\n    * Optimizing model serving through tools like post-training quantization.\n  * **Challenges and Solutions:**\n    * Addressing query latency and document retrieval efficiency using dynamic batching and model quantization.\n    * Utilizing techniques like contrastive learning to train models effectively.\n  * **Practical Strategies:** The presentation also covered strategies for transitioning embedding models from research to production while ensuring high performance and scalability.\n\n\nThis is the end of the AI-generated content.\n* * *\n### Abstract\nEmbedding models are at the core of search, recommendation, and retrieval-augmented generation (RAG) systems, transforming data into meaningful representations. We can adapt state-of-the-art large language models (LLMs) into embedding models that generate high-quality embeddings, but deploying these models in large-scale applications presents significant challenges.\nThis talk explores the end-to-end lifecycle of embedding systems, including:\n  * Leveraging LLMs for high-quality embeddings and adapting them for domain-specific use cases using contrastive learning.\n  * Designing custom architectures optimized for use-case specific serving requirements.\n  * Distilling large embedding models into smaller, production-friendly sizes.\n  * Serving embeddings efficiently with optimization strategies like variable batch sizes and post-training quantization.\n\n\nAttendees will leave with practical strategies for scaling embedding models from research to production, ensuring high performance and efficiency in real-world applications like retrieving best matching documents, passages or images, data de-duplication, generating personalized recommendations, content clustering, and grounding GenAI responses using RAG approach.\n* * *\n### Speaker\n#### Sahil Dua\nSenior Software Engineer, Machine Learning @Google, Stanford AI, Co-Author of \u201cThe Kubernetes Workshop\u201d, Open-Source Enthusiast \nSahil Dua is a Tech Lead focused on developing and adapting large language models (LLMs) with an expertise in Representation Learning. He oversees the full LLM lifecycle, from designing data pipelines and model architectures to optimizing models for highly efficient serving. Before Google, Sahil worked on the ML platform at Booking.com to scale machine learning model development and deployment.\nA co-author of \u201cThe Kubernetes Workshop\u201d book and an open-source enthusiast, Sahil has contributed to projects like Git, Pandas, and Linguist. As a frequent speaker at global conferences, he shares insights on AI, machine learning, and tech innovation, inspiring professionals across the industry.\nRead more\n#####  Find Sahil Dua at: \n  *   * \n\n#### Speaker\n##### Sahil Dua\nSenior Software Engineer, Machine Learning @Google, Stanford AI, Co-Author of \u201cThe Kubernetes Workshop\u201d, Open-Source Enthusiast \n#### Date\nTuesday Apr 8 / 03:55PM BST ( 50 minutes )\n#### Location\nChurchill (Ground Fl.)\n#### Track\nAI and ML for Software Engineers: Foundational Insights\n#### Topics\nAI/ML embedding models rag\n#### Slides\nSlides are not available\n#### Share\nShare Share\n## From the same track\nSession AI/ML\n### Deploy MultiModal RAG Systems with vLLM\nTuesday Apr 8 / 10:35AM BST\nWhile text-based RAG systems have been everywhere in the last year and a half, there is so much more than text data. Images, audio, and documents often need to be processed together to provide meaningful insights, yet most RAG implementations focus solely on text. \nStephen Batifol\nDeveloper Advocate @Zilliz, Founding Member of the MLOps Community Berlin, Previously Machine Learning Engineer @Wolt, and Data Scientist @Brevo\nDeploy MultiModal RAG Systems with vLLM\nSession AI/ML\n### How to Unlock Insights and Enable Discovery Within Petabytes of Autonomous Driving Data\nTuesday Apr 8 / 05:05PM BST\nFor autonomous vehicle companies, finding valuable insights within millions of hours of video data is essential yet challenging. \nKyra Mozley\nML Engineer @Wayve, Previously Security & AI PhD Candidate @Royal Holloway University\nHow to Unlock Insights and Enable Discovery Within Petabytes of Autonomous Driving Data\nSession AI/ML\n### AI for Food Image Generation in Production: How & Why\nTuesday Apr 8 / 01:35PM BST\nIn this talk, we will conduct a technical overview of a client-facing Food Image Generation solution developed at Delivery Hero. \nIaroslav Amerkhanov\nSenior Data Scientist @Delivery Hero, Founder of T4lky, Creator & Host of EPAM Podcast, Speaker\nAI for Food Image Generation in Production: How & Why\nSession AI/ML\n### Foundation Models for Ranking: Challenges, Successes, and Lessons Learned\nTuesday Apr 8 / 02:45PM BST\nRecommender systems are an integral part of most products nowadays and are often a key driver of discovery for users of the product. \nMoumita Bhattacharya\nSenior Research Scientist @Netflix, Previously @Etsy\nFoundation Models for Ranking: Challenges, Successes, and Lessons Learned\nSession\n### Unconference: AI and ML for Software Engineers\nTuesday Apr 8 / 11:45AM BST\nUnconference: AI and ML for Software Engineers\n"
}